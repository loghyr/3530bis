<!-- Copyright (C) The IETF Trust (2009-2011) -->
<!-- Copyright (C) The Internet Society (2010-2011) -->
<section anchor="sec:name_space" title="NFS Server Name Space">

  <section title="Server Exports">

    <t>
      On a UNIX server the name space describes all the files reachable by
      pathnames under the root directory or "/".  On a Windows NT server
      the name space constitutes all the files on disks named by mapped
      disk letters.  NFS server administrators rarely make the entire
      server's file system name space available to NFS clients.  More often
      portions of the name space are made available via an "export" feature.
      In previous versions of the NFS protocol, the root filehandle for
      each export is obtained through the MOUNT protocol; the client sends
      a string that identifies an object in the exported name space and the server
      returns the root filehandle for it.  The MOUNT protocol supports an
      EXPORTS procedure that will enumerate the server's exports.
    </t>

  </section>
  <section title="Browsing Exports">

    <t>
      The NFSv4 protocol provides a root filehandle that clients
      can use to obtain filehandles for these exports via a multi-component
      LOOKUP.  A common user experience is to use a graphical user interface
      (perhaps a file "Open" dialog window) to find a file via progressive
      browsing through a directory tree.  The client must be able to move
      from one export to another export via single-component, progressive
      LOOKUP operations.
    </t>

    <t>
      This style of browsing is not well supported by the NFSv2 and
      NFSv3 protocols.  The client expects all LOOKUP operations to remain
      within a single server file system.  For example, the device attribute
      will not change.  This prevents a client from taking name space
      paths that span exports.
    </t>

    <t>
      An automounter on the client can obtain a snapshot of the server's
      name space using the EXPORTS procedure of the MOUNT protocol.  If it
      understands the server's pathname syntax, it can create an image of
      the server's name space on the client.  The parts of the name
      space that are not exported by the server are filled in with a
      "pseudo file system" that allows the user to browse from one mounted
      file system to another.  There is a drawback to this representation of
      the server's name space on the client: it is static.  If the server
      administrator adds a new export the client will be unaware of it.
    </t>

  </section>
  <section title="Server Pseudo Filesystem">

    <t>
      NFSv4 servers avoid this name space inconsistency by
      presenting all the exports within the framework of a single server
      name space.  An NFSv4 client uses LOOKUP and READDIR
      operations to browse seamlessly from one export to another.  Portions
      of the server name space that are not exported are bridged via a
      "pseudo file system" that provides a view of exported directories only.
      A pseudo file system has a unique fsid and behaves like a normal,
      read only file system.
    </t>

    <t>
      Based on the construction of the server's name space, it is possible
      that multiple pseudo file systems may exist.  For example,

      <figure>
        <artwork>
  /a         pseudo file system
  /a/b       real file system
  /a/b/c     pseudo file system
  /a/b/c/d   real file system
        </artwork>
      </figure>
    </t>

    <t>
      Each of the pseudo file systems are considered separate entities and
      therefore will have a unique fsid.
    </t>

  </section>
  <section title="Multiple Roots">

    <t>
      The DOS and Windows operating environments are sometimes described
      as having "multiple roots".  Filesystems are commonly represented
      as disk letters.  MacOS represents file systems as top level names.
      NFSv4 servers for these platforms can construct a pseudo
      file system above these root names so that disk letters or volume
      names are simply directory names in the pseudo root.
    </t>

  </section>
  <section title="Filehandle Volatility">

    <t>
      The nature of the server's pseudo file system is that it is a logical
      representation of file system(s) available from the server.  Therefore,
      the pseudo file system is most likely constructed dynamically when
      the server is first instantiated.  It is expected that the pseudo
      file system may not have an on disk counterpart from which persistent
      filehandles could be constructed.  Even though it is preferable that
      the server provide persistent filehandles for the pseudo file system,
      the NFS client should expect that pseudo file system filehandles
      are volatile.  This can be confirmed by checking the associated
      "fh_expire_type" attribute for those filehandles in question.
      If the filehandles are volatile, the NFS client must be prepared
      to recover a filehandle value (e.g., with a multi-component LOOKUP)
      when receiving an error of NFS4ERR_FHEXPIRED.
    </t>

  </section>
  <section title="Exported Root">

    <t>
      If the server's root file system is exported, one might conclude that
      a pseudo file system is not needed.  This would be wrong.  Assume the
      following file systems on a server:

      <figure>
        <artwork>
  /       disk1  (exported)
  /a      disk2  (not exported)
  /a/b    disk3  (exported)
        </artwork>
      </figure>
    </t>

    <t>
      Because disk2 is not exported, disk3 cannot be reached with simple
      LOOKUPs.  The server must bridge the gap with a pseudo file system.
    </t>

  </section>
  <section title="Mount Point Crossing">

    <t>
      The server file system environment may be constructed in such a
      way that one file system contains a directory which is 'covered'
      or mounted upon by a second file system.  For example:

      <figure>
        <artwork>
  /a/b            (file system 1)
  /a/b/c/d        (file system 2)
        </artwork>
      </figure>
    </t>

    <t>
      The pseudo file system for this server may be constructed to look like:

      <figure>
        <artwork>
  /               (place holder/not exported)
  /a/b            (file system 1)
  /a/b/c/d        (file system 2)
        </artwork>
      </figure>
    </t>

    <t>
      It is the server's responsibility to present the pseudo file system
      that is complete to the client.  If the client sends a lookup request
      for the path "/a/b/c/d", the server's response is the filehandle of
      the file system "/a/b/c/d".  In previous versions of the NFS protocol,
      the server would respond with the filehandle of directory "/a/b/c/d"
      within the file system "/a/b".
    </t>

    <t>
      The NFS client will be able to determine if it crosses a server
      mount point by a change in the value of the "fsid" attribute.
    </t>

  </section>
  <section title="Security Policy and Name Space Presentation">

    <t>
      The application of the server's security policy needs to be carefully
      considered by the implementor.  One may choose to limit the
      viewability of portions of the pseudo file system based on the
      server's perception of the client's ability to authenticate
      itself properly.  However, with the support of multiple security
      mechanisms and the ability to negotiate the appropriate use of these
      mechanisms, the server is unable to properly determine if a client
      will be able to authenticate itself.  If, based on its policies,
      the server chooses to limit the contents of the pseudo file system,
      the server may effectively hide file systems from a client that may
      otherwise have legitimate access.
    </t>

    <t>
      As suggested practice, the server should apply the security policy of
      a shared resource in the server's namespace to the components of
      the resource's ancestors.  For example:

      <figure>
        <artwork>
  /
  /a/b
  /a/b/c
        </artwork>
      </figure>
    </t>

    <t>
      The /a/b/c directory is a real file system and is the shared resource.
      The security policy for /a/b/c is Kerberos with integrity.  The server
      should apply the same security policy to /, /a, and /a/b.  This allows
      for the extension of the protection of the server's namespace to
      the ancestors of the real shared resource.
    </t>

    <t>
      For the case of the use of multiple, disjoint security mechanisms in
      the server's resources, the security for a particular object in the
      server's namespace should be the union of all security mechanisms
      of all direct descendants.
    </t>
  </section>
</section>
