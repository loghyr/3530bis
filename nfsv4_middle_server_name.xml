<!-- Copyright (C) The IETF Trust (2007-2008) -->
<!-- Copyright (C) The Internet Society (2006) -->
<section anchor="sec:name_space" title="NFS Server Name Space">

  <section title="Server Exports">

    <t>
      On a UNIX server the name space describes all the files reachable by
      pathnames under the root directory or "/".  On a Windows NT server
      the name space constitutes all the files on disks named by mapped
      disk letters.  NFS server administrators rarely make the entire
      server's filesystem name space available to NFS clients.  More often
      portions of the name space are made available via an "export" feature.
      In previous versions of the NFS protocol, the root filehandle for
      each export is obtained through the MOUNT protocol; the client sends
      a string that identifies the export of name space and the server
      returns the root filehandle for it.  The MOUNT protocol supports an
      EXPORTS procedure that will enumerate the server's exports.
    </t>

  </section>
  <section title="Browsing Exports">

    <t>
      The NFS version 4 protocol provides a root filehandle that clients
      can use to obtain filehandles for these exports via a multi-component
      LOOKUP.  A common user experience is to use a graphical user interface
      (perhaps a file "Open" dialog window) to find a file via progressive
      browsing through a directory tree.  The client must be able to move
      from one export to another export via single-component, progressive
      LOOKUP operations.
    </t>

    <t>
      This style of browsing is not well supported by the NFS version 2 and
      3 protocols.  The client expects all LOOKUP operations to remain
      within a single server filesystem.  For example, the device attribute
      will not change.  This prevents a client from taking name space
      paths that span exports.
    </t>

    <t>
      An automounter on the client can obtain a snapshot of the server's
      name space using the EXPORTS procedure of the MOUNT protocol.  If it
      understands the server's pathname syntax, it can create an image of
      the server's name space on the client.  The parts of the name
      space that are not exported by the server are filled in with a
      "pseudo filesystem" that allows the user to browse from one mounted
      filesystem to another.  There is a drawback to this representation of
      the server's name space on the client: it is static.  If the server
      administrator adds a new export the client will be unaware of it.
    </t>

  </section>
  <section title="Server Pseudo Filesystem">

    <t>
      NFS version 4 servers avoid this name space inconsistency by
      presenting all the exports within the framework of a single server
      name space.  An NFS version 4 client uses LOOKUP and READDIR
      operations to browse seamlessly from one export to another.  Portions
      of the server name space that are not exported are bridged via a
      "pseudo filesystem" that provides a view of exported directories only.
      A pseudo filesystem has a unique fsid and behaves like a normal,
      read only filesystem.
    </t>

    <t>
      Based on the construction of the server's name space, it is possible
      that multiple pseudo filesystems may exist.  For example,

      <figure>
        <artwork>
/a         pseudo filesystem
/a/b       real filesystem
/a/b/c     pseudo filesystem
/a/b/c/d   real filesystem
        </artwork>
      </figure>
    </t>

    <t>
      Each of the pseudo filesystems are considered separate entities and
      therefore will have a unique fsid.
    </t>

  </section>
  <section title="Multiple Roots">

    <t>
      The DOS and Windows operating environments are sometimes described
      as having "multiple roots".  Filesystems are commonly represented
      as disk letters.  MacOS represents filesystems as top level names.
      NFS version 4 servers for these platforms can construct a pseudo
      file system above these root names so that disk letters or volume
      names are simply directory names in the pseudo root.
    </t>

  </section>
  <section title="Filehandle Volatility">

    <t>
      The nature of the server's pseudo filesystem is that it is a logical
      representation of filesystem(s) available from the server.  Therefore,
      the pseudo filesystem is most likely constructed dynamically when
      the server is first instantiated.  It is expected that the pseudo
      filesystem may not have an on disk counterpart from which persistent
      filehandles could be constructed.  Even though it is preferable that
      the server provide persistent filehandles for the pseudo filesystem,
      the NFS client should expect that pseudo file system filehandles
      are volatile.  This can be confirmed by checking the associated
      "fh_expire_type" attribute for those filehandles in question.
      If the filehandles are volatile, the NFS client must be prepared
      to recover a filehandle value (e.g., with a multi-component LOOKUP)
      when receiving an error of NFS4ERR_FHEXPIRED.
    </t>

  </section>
  <section title="Exported Root">

    <t>
      If the server's root filesystem is exported, one might conclude that
      a pseudo-filesystem is not needed.  This would be wrong.  Assume the
      following filesystems on a server:

      <figure>
        <artwork>
/       disk1  (exported)
/a      disk2  (not exported)
/a/b    disk3  (exported)
        </artwork>
      </figure>
    </t>

    <t>
      Because disk2 is not exported, disk3 cannot be reached with simple
      LOOKUPs.  The server must bridge the gap with a pseudo-filesystem.
    </t>

  </section>
  <section title="Mount Point Crossing">

    <t>
      The server filesystem environment may be constructed in such a
      way that one filesystem contains a directory which is 'covered'
      or mounted upon by a second filesystem.  For example:

      <figure>
        <artwork>
/a/b            (filesystem 1)
/a/b/c/d        (filesystem 2)
        </artwork>
      </figure>
    </t>

    <t>
      The pseudo filesystem for this server may be constructed to look like:

      <figure>
        <artwork>
/               (place holder/not exported)
/a/b            (filesystem 1)
/a/b/c/d        (filesystem 2)
        </artwork>
      </figure>
    </t>

    <t>
      It is the server's responsibility to present the pseudo filesystem
      that is complete to the client.  If the client sends a lookup request
      for the path "/a/b/c/d", the server's response is the filehandle of
      the filesystem "/a/b/c/d".  In previous versions of the NFS protocol,
      the server would respond with the filehandle of directory "/a/b/c/d"
      within the filesystem "/a/b".
    </t>

    <t>
      The NFS client will be able to determine if it crosses a server
      mount point by a change in the value of the "fsid" attribute.
    </t>

  </section>
  <section title="Security Policy and Name Space Presentation">

    <t>
      The application of the server's security policy needs to be carefully
      considered by the implementor.  One may choose to limit the
      viewability of portions of the pseudo filesystem based on the
      server's perception of the client's ability to authenticate
      itself properly.  However, with the support of multiple security
      mechanisms and the ability to negotiate the appropriate use of these
      mechanisms, the server is unable to properly determine if a client
      will be able to authenticate itself.  If, based on its policies,
      the server chooses to limit the contents of the pseudo filesystem,
      the server may effectively hide filesystems from a client that may
      otherwise have legitimate access.
    </t>

    <t>
      As suggested practice, the server should apply the security policy of
      a shared resource in the server's namespace to the components of
      the resource's ancestors.  For example:

      <figure>
        <artwork>
/
/a/b
/a/b/c
        </artwork>
      </figure>
    </t>

    <t>
      The /a/b/c directory is a real filesystem and is the shared resource.
      The security policy for /a/b/c is Kerberos with integrity.  The server
      should apply the same security policy to /, /a, and /a/b.  This allows
      for the extension of the protection of the server's namespace to
      the ancestors of the real shared resource.
    </t>

    <t>
      For the case of the use of multiple, disjoint security mechanisms in
      the server's resources, the security for a particular object in the
      server's namespace should be the union of all security mechanisms
      of all direct descendants.
    </t>
  </section>
</section>
